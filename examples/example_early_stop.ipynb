{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683cffe5",
   "metadata": {},
   "source": [
    "# XGBoost Regression with TensorFlow Pooling and Loss\n",
    "## Tutorial on early stopping\n",
    "This tutorial demonstrates the use of `xgb_tf_metric` decorator for early stopping. For a more comprehensive tutorial on how to use `tf2xgb` library, please refer to [this](example.ipynb) example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8541af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janhe\\OneDrive\\Plocha\\repos\\tf2xgb\\env\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf2xgb import get_ragged_nested_index_lists, gen_random_dataset, xgb_tf_loss, xgb_tf_metric\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264434fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "N_SUBGRP = N//2\n",
    "N_GRP = 0 # we will use only one level of pooling in this tutorial\n",
    "BETA_TRUE = [2,1,0,0,0]\n",
    "SIGMA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9653bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main data frame with features X, subgroup IDs subgrp_id and group ID grp_id;\n",
    "# target y is NOT observable on the individual level in real data,\n",
    "# we have it here to be able to simulate target on group level\n",
    "# and to be able to compared result of the estimate on the group-level\n",
    "# target with the estimate on the individual level.\n",
    "df_train = gen_random_dataset(N, N_SUBGRP, N_GRP, BETA_TRUE, SIGMA)\n",
    "df_val = gen_random_dataset(N, N_SUBGRP, N_GRP, BETA_TRUE, SIGMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c123d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_row_</th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>subgrp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.990320213665162, -0.9073304936192282, 1.435...</td>\n",
       "      <td>0.702018</td>\n",
       "      <td>SUBGRP0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.0007154451546965, 0.11364963136298611, 0.10...</td>\n",
       "      <td>2.432624</td>\n",
       "      <td>SUBGRP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.9489771875967585, 0.5654649942882454, -1.3...</td>\n",
       "      <td>-0.710235</td>\n",
       "      <td>SUBGRP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[1.4588152857051915, -0.6525509713800075, -0.1...</td>\n",
       "      <td>4.482466</td>\n",
       "      <td>SUBGRP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[0.007055279881034012, -1.7218724585797522, -0...</td>\n",
       "      <td>-0.695231</td>\n",
       "      <td>SUBGRP4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _row_                                                  X         y  \\\n",
       "0      0  [0.990320213665162, -0.9073304936192282, 1.435...  0.702018   \n",
       "1      1  [1.0007154451546965, 0.11364963136298611, 0.10...  2.432624   \n",
       "2      2  [-0.9489771875967585, 0.5654649942882454, -1.3... -0.710235   \n",
       "3      3  [1.4588152857051915, -0.6525509713800075, -0.1...  4.482466   \n",
       "4      4  [0.007055279881034012, -1.7218724585797522, -0... -0.695231   \n",
       "\n",
       "  subgrp_id  \n",
       "0   SUBGRP0  \n",
       "1   SUBGRP1  \n",
       "2   SUBGRP2  \n",
       "3   SUBGRP3  \n",
       "4   SUBGRP4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a233781",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(df_train['X'].to_list())\n",
    "y_train = np.asarray(df_train['y'].to_list())\n",
    "X_val = np.asarray(df_val['X'].to_list())\n",
    "y_val = np.asarray(df_val['y'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4468f76c",
   "metadata": {},
   "source": [
    "Calculate simulated target `y` on the level of `subgrp_id` (by max pooling of individual-level `y`'s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ea695e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_subgrp_y = (df_train\n",
    "    .groupby('subgrp_id')\n",
    "    .agg({'y':np.max})\n",
    "    .reset_index()\n",
    ")\n",
    "df_train_subgrp_inds = get_ragged_nested_index_lists(df_train, ['subgrp_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "676fb765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_subgrp_y = (df_val\n",
    "    .groupby('subgrp_id')\n",
    "    .agg({'y':np.max})\n",
    "    .reset_index()\n",
    ")\n",
    "df_val_subgrp_inds = get_ragged_nested_index_lists(df_val, ['subgrp_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21312c0",
   "metadata": {},
   "source": [
    "## Custom TF Pooling and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "561be8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@xgb_tf_loss(df_train_subgrp_inds.sort_values(by=['subgrp_id'])['_row_'].to_list(), \n",
    "             df_train_subgrp_y.sort_values(by=['subgrp_id'])['y'].to_numpy())\n",
    "def max_pooling_mse_loss(target, preds_cube):\n",
    "    \"\"\"Custom TF Pooling and Loss function.\n",
    "\n",
    "    This example function performs max pooling from the individual\n",
    "    level to subgroups.\n",
    "    The function takes appropriate care of missing values in preds_cube.\n",
    "\n",
    "    Inputs:\n",
    "    = target: 1D tensor with target on the level of groups\n",
    "    = preds_cube: ND tensor with predictions on the individual level;\n",
    "    the first dimension is that of groups, the other dimensions reflect\n",
    "    sub-groups on different levels and individual observations\n",
    "    (target.shape[0] == preds_cube.shape[0]; \n",
    "    preds_cube.shape[-1] == max # indiv observations per the most detailed \n",
    "    sub-group).\n",
    "    Missing values are denoted by np.nan and have to be taken care of in \n",
    "    this function body. They occur simply because preds_cube\n",
    "    has typically much more elements that the original flat predictions\n",
    "    vector from XGBoost.\n",
    "\n",
    "    Output: scalar tensor reflecting MEAN of losses over all dimensions.\n",
    "    This is the output of e.g. tf.keras.losses.mean_squared_error().\n",
    "    The mean is translated to SUM later in tf_d_loss() because of the \n",
    "    compatibility with XGB custom objective function.\n",
    "    \"\"\"\n",
    "    x = preds_cube\n",
    "    # replace NaNs with -Inf: neutral value for reduce_max()\n",
    "    x = tf.where(tf.math.is_nan(x), tf.constant(-np.inf, dtype=x.dtype), x)\n",
    "    x = tf.math.reduce_max(x, axis=-1)\n",
    "    l = tf.keras.losses.mean_squared_error(target, x)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aea6660",
   "metadata": {},
   "source": [
    "## Custom Pooling Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af1940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@xgb_tf_metric(df_val_subgrp_inds.sort_values(by=['subgrp_id'])['_row_'].to_list(), \n",
    "               df_val_subgrp_y.sort_values(by=['subgrp_id'])['y'].to_numpy())\n",
    "def max_pooling_mse_metric(target, preds_cube):\n",
    "    \"\"\"Custom Pooling MSE.\n",
    "\n",
    "    This example function performs max pooling from the individual\n",
    "    level to subgroups and computes MSE.\n",
    "    The function takes appropriate care of missing values in preds_cube.\n",
    "\n",
    "    Inputs:\n",
    "    = target: 1D tensor with target on the level of groups\n",
    "    = preds_cube: ND tensor with predictions on the individual level;\n",
    "    the first dimension is that of groups, the other dimensions reflect\n",
    "    sub-groups on different levels and individual observations\n",
    "    (target.shape[0] == preds_cube.shape[0]; \n",
    "    preds_cube.shape[-1] == max # indiv observations per the most detailed \n",
    "    sub-group).\n",
    "    Missing values are denoted by np.nan and have to be taken care of in \n",
    "    this function body. They occur simply because preds_cube\n",
    "    has typically much more elements that the original flat predictions\n",
    "    vector from XGBoost.\n",
    "\n",
    "    Output: tuple (metric_name, metric_value)\n",
    "    \"\"\"\n",
    "    preds_cube = np.nan_to_num(preds_cube, nan=-np.inf)\n",
    "    preds = np.max(preds_cube, axis=-1)\n",
    "    score = mean_squared_error(target, preds)\n",
    "    return 'max_mse', score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58682dad",
   "metadata": {},
   "source": [
    "## Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3ad76ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train)\n",
    "dval = xgb.DMatrix(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37630483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tval-max_mse:4.43615\n",
      "[1]\tval-max_mse:3.65869\n",
      "[2]\tval-max_mse:3.05419\n",
      "[3]\tval-max_mse:2.58527\n",
      "[4]\tval-max_mse:2.22042\n",
      "[5]\tval-max_mse:1.93740\n",
      "[6]\tval-max_mse:1.71603\n",
      "[7]\tval-max_mse:1.54372\n",
      "[8]\tval-max_mse:1.41002\n",
      "[9]\tval-max_mse:1.30572\n",
      "[10]\tval-max_mse:1.22442\n",
      "[11]\tval-max_mse:1.16187\n",
      "[12]\tval-max_mse:1.11270\n",
      "[13]\tval-max_mse:1.07487\n",
      "[14]\tval-max_mse:1.04528\n",
      "[15]\tval-max_mse:1.02249\n",
      "[16]\tval-max_mse:1.00472\n",
      "[17]\tval-max_mse:0.99116\n",
      "[18]\tval-max_mse:0.98074\n",
      "[19]\tval-max_mse:0.97254\n",
      "[20]\tval-max_mse:0.96643\n",
      "[21]\tval-max_mse:0.96143\n",
      "[22]\tval-max_mse:0.95773\n",
      "[23]\tval-max_mse:0.95515\n",
      "[24]\tval-max_mse:0.95302\n",
      "[25]\tval-max_mse:0.95140\n",
      "[26]\tval-max_mse:0.95026\n",
      "[27]\tval-max_mse:0.94930\n",
      "[28]\tval-max_mse:0.94863\n",
      "[29]\tval-max_mse:0.94814\n",
      "[30]\tval-max_mse:0.94787\n",
      "[31]\tval-max_mse:0.94759\n",
      "[32]\tval-max_mse:0.94749\n",
      "[33]\tval-max_mse:0.94742\n",
      "[34]\tval-max_mse:0.94748\n",
      "[35]\tval-max_mse:0.94745\n",
      "[36]\tval-max_mse:0.94749\n",
      "CPU times: total: 54.6 s\n",
      "Wall time: 38.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr_subgrp = xgb.train({'tree_method': 'hist',\n",
    "                         'seed': 1994,\n",
    "                         'n_jobs': 20,\n",
    "                         'learning_rate': 0.12,\n",
    "                         'disable_default_eval_metric': 1\n",
    "                        }, \n",
    "                        num_boost_round=100,\n",
    "                        dtrain=dtrain,\n",
    "                        evals=[(dval, 'val')],\n",
    "                        obj=max_pooling_mse_loss,\n",
    "                        feval=max_pooling_mse_metric,\n",
    "                        early_stopping_rounds=3\n",
    "                       )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
